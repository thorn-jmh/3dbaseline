{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b579c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19288\\3381903573.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridspec\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_utils'"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "from random import expovariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow.compat.v1 as tf\n",
    "import data_utils\n",
    "import viz\n",
    "import re\n",
    "import cameras\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from predict_3dpose import create_model\n",
    "import cv2\n",
    "import imageio\n",
    "import logging\n",
    "import scipy as sp\n",
    "from pprint import pprint\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "order = [15, 12, 25, 26, 27, 17, 18, 19, 1, 2, 3, 6, 7, 8]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def show_anim_curves(anim_dict, _plt):\n",
    "    # pdb.set_trace()\n",
    "    val = np.array(list(anim_dict.values()))\n",
    "    #读取所有帧的某个节点的 x,y 坐标\n",
    "    for o in range(0,36,2):\n",
    "        x = val[:,o]\n",
    "        y = val[:,o+1]\n",
    "        #红色虚线\n",
    "        _plt.plot(x, 'r--', linewidth=0.2)\n",
    "        #绿色\n",
    "        _plt.plot(y, 'g', linewidth=0.2)\n",
    "    return _plt\n",
    "\n",
    "#读入2d_json文件\n",
    "def read_openpose_json(smooth=True, *args):\n",
    "    # openpose output format:\n",
    "    # [x1,y1,c1,x2,y2,c2,...]\n",
    "    # ignore confidence score, take x and y [x1,y1,x2,y2,...]\n",
    "\n",
    "    logger.info(\"start reading json files\")\n",
    "    #load json files\n",
    "    json_files = os.listdir(openpose_output_dir)\n",
    "    json_files = [file_name for file_name in json_files if file_name.endswith(\".json\")]\n",
    "    # check for other file types\n",
    "    #改成了sort\n",
    "    json_files.sort(key=lambda x: int(x[:-5]))\n",
    "    # pdb.set_trace()\n",
    "    #cache dict\n",
    "    cache = {}\n",
    "    #\n",
    "    smoothed = {}\n",
    "    ### extract x,y and ignore confidence score\n",
    "    for file_name in json_files:\n",
    "        logger.debug(\"reading {0}\".format(file_name))\n",
    "        _file = os.path.join(openpose_output_dir, file_name)\n",
    "        if not os.path.isfile(_file): raise Exception(\"No file found!!, {0}\".format(_file))\n",
    "        data = json.load(open(_file))\n",
    "        #take first person\n",
    "        _data = data[\"people\"][0][\"pose_keypoints_2d\"] if \"pose_keypoints_2d\" in data[\"people\"][0] else data[\"people\"][0][\"pose_keypoints\"]\n",
    "        xy = []\n",
    "        if len(_data)>=53:\n",
    "            #openpose incl. confidence score\n",
    "            #ignore confidence score\n",
    "            for o in range(0,len(_data),3):\n",
    "                xy.append(_data[o])\n",
    "                xy.append(_data[o+1])\n",
    "        else:\n",
    "            #tf-pose-estimation\n",
    "            xy = _data\n",
    "\n",
    "        # get frame index from openpose 12 padding\n",
    "        frame_indx = re.findall(\"(\\d+)\", file_name)\n",
    "        logger.debug(\"found {0} for frame {1}\".format(xy, str(int(frame_indx[-1]))))\n",
    "\n",
    "        #body_25 support, convert body_25 output format to coco\n",
    "        if len(_data)>54:\n",
    "            # pdb.set_trace()\n",
    "            _xy = xy[0:19*2]\n",
    "            for x in range(len(xy)):\n",
    "                #del jnt 8\n",
    "                if x==8*2:\n",
    "                    del _xy[x]\n",
    "                if x==8*2+1:\n",
    "                    del _xy[x]\n",
    "                #map jnt 9 to 8\n",
    "                if x==9*2:\n",
    "                    _xy[16] = xy[x]\n",
    "                    _xy[17] = xy[x+1]\n",
    "                #map jnt 10 to 9\n",
    "                if x==10*2:\n",
    "                    _xy[18] = xy[x]\n",
    "                    _xy[19] = xy[x+1]         \n",
    "                #map jnt 11 to 10\n",
    "                if x==11*2:\n",
    "                    _xy[20] = xy[x]\n",
    "                    _xy[21] = xy[x+1]\n",
    "                #map jnt 12 to 11\n",
    "                if x==12*2:\n",
    "                    _xy[22] = xy[x]\n",
    "                    _xy[23] = xy[x+1]\n",
    "                #map jnt 13 to 12\n",
    "                if x==13*2:\n",
    "                    _xy[24] = xy[x]\n",
    "                    _xy[25] = xy[x+1]         \n",
    "                #map jnt 14 to 13\n",
    "                if x==14*2:\n",
    "                    _xy[26] = xy[x]\n",
    "                    _xy[27] = xy[x+1]\n",
    "                #map jnt 15 to 14\n",
    "                if x==15*2:\n",
    "                    _xy[28] = xy[x]\n",
    "                    _xy[29] = xy[x+1]\n",
    "                #map jnt 16 to 15\n",
    "                if x==16*2:\n",
    "                    _xy[30] = xy[x]\n",
    "                    _xy[31] = xy[x+1]\n",
    "                #map jnt 17 to 16\n",
    "                if x==17*2:\n",
    "                    _xy[32] = xy[x]\n",
    "                    _xy[33] = xy[x+1]\n",
    "                #map jnt 18 to 17\n",
    "                if x==18*2:\n",
    "                    _xy[34] = xy[x]\n",
    "                    _xy[35] = xy[x+1]\n",
    "            #coco \n",
    "            xy = _xy\n",
    "\n",
    "        #add xy to frame\n",
    "        cache[int(frame_indx[-1])] = xy\n",
    "\n",
    "    # pdb.set_trace()DEBUG:\n",
    "    plt.figure(1)\n",
    "    #某个节点坐标的变化曲线\n",
    "    drop_curves_plot = show_anim_curves(cache, plt)\n",
    "    pngName = 'F:\\\\WTF\\cs\\\\thorn-jmh\\\\3d-pose-baseline\\\\test\\\\gif_output\\\\dirty_plot.png' #TODO:\n",
    "    drop_curves_plot.savefig(pngName)\n",
    "    logger.info('writing gif_output/dirty_plot.png')\n",
    "\n",
    "    # exit if no smoothing\n",
    "    if not smooth:\n",
    "        # return frames cache incl. 18 joints (x,y)\n",
    "        return cache\n",
    "\n",
    "    if len(json_files) == 1:\n",
    "        logger.info(\"found single json file\")\n",
    "        # return frames cache incl. 18 joints (x,y) on single image\\json\n",
    "        return cache\n",
    "\n",
    "    if len(json_files) <= 8:\n",
    "        raise Exception(\"need more frames, min 9 frames/json files for smoothing!!!\")\n",
    "\n",
    "    logger.info(\"start smoothing\")\n",
    "\n",
    "    # create frame blocks\n",
    "    head_frame_block = [int(re.findall(\"(\\d+)\", o)[-1]) for o in json_files[:4]]\n",
    "    tail_frame_block = [int(re.findall(\"(\\d+)\", o)[-1]) for o in json_files[-4:]]\n",
    "\n",
    "    ### smooth by median value, n frames \n",
    "    #通过临近 3 帧坐标中位数确定smooth坐标\n",
    "    for frame, xy in cache.items():\n",
    "        # create neighbor array based on frame index\n",
    "        forward, back = ([] for _ in range(2))\n",
    "        # pdb.set_trace()\n",
    "        # joints x,y array\n",
    "        _len = len(xy) # 36\n",
    "\n",
    "        # create array of parallel frames (-3<n>3)\n",
    "        for neighbor in range(1,4):\n",
    "            # first n frames, get value of xy in postive lookahead frames(current frame + 3)\n",
    "            if frame in head_frame_block:\n",
    "                forward += cache[frame+neighbor]\n",
    "            # last n frames, get value of xy in negative lookahead frames(current frame - 3)\n",
    "            elif frame in tail_frame_block:\n",
    "                back += cache[frame-neighbor]\n",
    "            else:\n",
    "                # between frames, get value of xy in bi-directional frames(current frame -+ 3)     \n",
    "                forward += cache[frame+neighbor]\n",
    "                back += cache[frame-neighbor]\n",
    "\n",
    "        # build frame range vector \n",
    "        frames_joint_median = [0 for i in range(_len)]\n",
    "        # more info about mapping in src/data_utils.py\n",
    "        # for each 18joints*x,y  (x1,y1,x2,y2,...)~36 \n",
    "        for x in range(0,_len,2):\n",
    "            # set x and y\n",
    "            y = x+1\n",
    "            if frame in head_frame_block:\n",
    "                # get vector of n frames forward for x and y, incl. current frame\n",
    "                x_v = [xy[x], forward[x], forward[x+_len], forward[x+_len*2]]\n",
    "                y_v = [xy[y], forward[y], forward[y+_len], forward[y+_len*2]]\n",
    "            elif frame in tail_frame_block:\n",
    "                # get vector of n frames back for x and y, incl. current frame\n",
    "                x_v =[xy[x], back[x], back[x+_len], back[x+_len*2]]\n",
    "                y_v =[xy[y], back[y], back[y+_len], back[y+_len*2]]\n",
    "            else:\n",
    "                # get vector of n frames forward/back for x and y, incl. current frame\n",
    "                # median value calc: find neighbor frames joint value and sorted them, use numpy median module\n",
    "                # frame[x1,y1,[x2,y2],..]frame[x1,y1,[x2,y2],...], frame[x1,y1,[x2,y2],..]\n",
    "                #                 ^---------------------|-------------------------^\n",
    "                x_v =[xy[x], forward[x], forward[x+_len], forward[x+_len*2],\n",
    "                        back[x], back[x+_len], back[x+_len*2]]\n",
    "                y_v =[xy[y], forward[y], forward[y+_len], forward[y+_len*2],\n",
    "                        back[y], back[y+_len], back[y+_len*2]]\n",
    "\n",
    "            # get median of vector\n",
    "            x_med = np.median(sorted(x_v))\n",
    "            y_med = np.median(sorted(y_v))\n",
    "\n",
    "            # holding frame drops for joint\n",
    "            if not x_med:\n",
    "                # allow fix from first frame\n",
    "                if frame:\n",
    "                    # get x from last frame\n",
    "                    x_med = smoothed[frame-1][x]\n",
    "            # if joint is hidden y\n",
    "            if not y_med:\n",
    "                # allow fix from first frame\n",
    "                if frame:\n",
    "                    # get y from last frame\n",
    "                    y_med = smoothed[frame-1][y]\n",
    "\n",
    "            logger.debug(\"old X {0} sorted neighbor {1} new X {2}\".format(xy[x],sorted(x_v), x_med))\n",
    "            logger.debug(\"old Y {0} sorted neighbor {1} new Y {2}\".format(xy[y],sorted(y_v), y_med))\n",
    "\n",
    "            # build new array of joint x and y value\n",
    "            frames_joint_median[x] = x_med \n",
    "            frames_joint_median[x+1] = y_med \n",
    "\t\t\n",
    "\n",
    "        smoothed[frame] = frames_joint_median\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "def save3Djson(pose3d, frame):\n",
    "    # pdb.set_trace()\n",
    "    export_units = {}\n",
    "    people = []\n",
    "    P = np.array([0,1,2,3,6,7,8,12,13,14,15,17,18,19,25,26,27])\n",
    "    vals = np.reshape( pose3d, (len(data_utils.H36M_NAMES), -1) )\n",
    "    for i in P :\n",
    "        for j in range(3):\n",
    "            people.append(vals[i,j])\n",
    "\n",
    "    export_units[\"version\"]=\"3d-base-line\"\n",
    "    export_units[\"pose_keypoints_3d\"]=people\n",
    "    _out_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'maya/seq-json/{0}.json'.format(str(frame)))\n",
    "    with open(_out_file, 'w') as outfile:\n",
    "        logger.info(\"exported maya json to {0}\".format(_out_file))\n",
    "        json.dump(export_units, outfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    #读json且smooth\n",
    "    smoothed = read_openpose_json()\n",
    "    #输出smooth后的坐标变化路径\n",
    "    plt.figure(2)\n",
    "    smooth_curves_plot = show_anim_curves(smoothed, plt)\n",
    "    #return\n",
    "    pngName = 'F:\\\\WTF\\cs\\\\thorn-jmh\\\\3d-pose-baseline\\\\test\\\\gif_output\\\\smooth_plot.png' #TODO:\n",
    "    smooth_curves_plot.savefig(pngName)\n",
    "    logger.info('writing gif_output/smooth_plot.png')\n",
    "    \n",
    "    #插帧\n",
    "    # pdb.set_trace()\n",
    "    if FLAGS.interpolation:\n",
    "        logger.info(\"start interpolation\")\n",
    "\n",
    "        framerange = len( smoothed.keys() )\n",
    "        joint_rows = 36\n",
    "        #将原来的dict转换为f*j的数组\n",
    "        array = np.concatenate(list(smoothed.values()))\n",
    "        array_reshaped = np.reshape(array, (framerange, joint_rows) )\n",
    "        #插帧间隔，默认0.1\n",
    "        multiplier = FLAGS.multiplier\n",
    "        multiplier_inv = 1/multiplier\n",
    "\n",
    "        out_array = np.array([])\n",
    "        for row in range(joint_rows):\n",
    "            #将全部的第 row 坐标插入x \n",
    "            x = []\n",
    "            for frame in range(framerange):\n",
    "                x.append( array_reshaped[frame, row] )\n",
    "            # pdb.set_trace()\n",
    "            frame = range( framerange )\n",
    "            frame_resampled = np.arange(0, framerange, multiplier)\n",
    "            #拟合曲线，k为平滑样条度数\n",
    "            spl = UnivariateSpline(frame, x, k=3)\n",
    "            #relative smooth factor based on jnt anim curve\n",
    "            min_x, max_x = min(x), max(x)\n",
    "            smooth_fac = max_x - min_x\n",
    "            smooth_resamp = 125\n",
    "            smooth_fac = smooth_fac * smooth_resamp\n",
    "            spl.set_smoothing_factor( float(smooth_fac) )\n",
    "            xnew = spl(frame_resampled)\n",
    "            \n",
    "            out_array = np.append(out_array, xnew)\n",
    "    \n",
    "        # pdb.set_trace()\n",
    "        logger.info(\"done interpolating. reshaping {0} frames,  please wait!!\".format(framerange))\n",
    "    \n",
    "        a = np.array([])\n",
    "        for frame in range( int( framerange * multiplier_inv ) ):\n",
    "            jnt_array = []\n",
    "            for jnt in range(joint_rows):\n",
    "                jnt_array.append( out_array[ jnt * int(framerange * multiplier_inv) + frame] )\n",
    "            a = np.append(a, jnt_array)\n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        a = np.reshape(a, (int(framerange * multiplier_inv), joint_rows))\n",
    "        out_array = a\n",
    "    \n",
    "        interpolate_smoothed = {}\n",
    "        for frame in range( int(framerange * multiplier_inv) ):\n",
    "            interpolate_smoothed[frame] = list( out_array[frame] )\n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        plt.figure(3)\n",
    "        smoothed = interpolate_smoothed\n",
    "        interpolate_curves_plot = show_anim_curves(smoothed, plt)\n",
    "        pngName = 'F:\\\\WTF\\cs\\\\thorn-jmh\\\\3d-pose-baseline\\\\test\\\\gif_output\\\\interpolate_{0}.png'.format(smooth_resamp)\n",
    "        interpolate_curves_plot.savefig(pngName)\n",
    "        logger.info('writing gif_output/interpolate_plot.png')\n",
    "\n",
    "    #prediction\n",
    "    # pdb.set_trace()\n",
    "    enc_in = np.zeros((1, 64))\n",
    "    enc_in[0] = [0 for i in range(64)]\n",
    "\n",
    "    actions = data_utils.define_actions(FLAGS.action)\n",
    "\n",
    "    SUBJECT_IDS = [1, 5, 6, 7, 8, 9, 11]\n",
    "    rcams = cameras.load_cameras(FLAGS.cameras_path, SUBJECT_IDS)\n",
    "    train_set_2d, test_set_2d, data_mean_2d, data_std_2d, dim_to_ignore_2d, dim_to_use_2d = data_utils.read_2d_predictions(\n",
    "        actions, FLAGS.data_dir)\n",
    "    train_set_3d, test_set_3d, data_mean_3d, data_std_3d, dim_to_ignore_3d, dim_to_use_3d, train_root_positions, test_root_positions = data_utils.read_3d_data(\n",
    "        actions, FLAGS.data_dir, FLAGS.camera_frame, rcams, FLAGS.predict_14)\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    device_count = {\"GPU\": 0}\n",
    "    png_lib = []\n",
    "    before_pose = None\n",
    "    with tf.Session(config=tf.ConfigProto(\n",
    "            device_count=device_count,\n",
    "            allow_soft_placement=True)) as sess:\n",
    "        #plt.figure(3)\n",
    "        batch_size = 128\n",
    "        model = create_model(sess, actions, batch_size)\n",
    "        iter_range = len(smoothed.keys())\n",
    "        export_units = {}\n",
    "        twod_export_units = {}\n",
    "        for n, (frame, xy) in enumerate(smoothed.items()):\n",
    "            logger.info(\"calc frame {0}/{1}\".format(frame, iter_range))\n",
    "            # map list into np array  \n",
    "            joints_array = np.zeros((1, 36))\n",
    "            joints_array[0] = [0 for i in range(36)]\n",
    "            for o in range(len(joints_array[0])):\n",
    "                #feed array with xy array\n",
    "                joints_array[0][o] = float(xy[o])\n",
    "\n",
    "            twod_export_units[frame]={}\n",
    "            for abs_b, __n in enumerate(range(0, len(xy),2)):\n",
    "                twod_export_units[frame][abs_b] = {\"translate\": [xy[__n],xy[__n+1]]}\n",
    "\n",
    "            _data = joints_array[0]\n",
    "            # mapping all body parts or 3d-pose-baseline format\n",
    "            for i in range(len(order)):\n",
    "                for j in range(2):\n",
    "                    # create encoder input\n",
    "                    enc_in[0][order[i] * 2 + j] = _data[i * 2 + j]\n",
    "            for j in range(2):\n",
    "                # Hip\n",
    "                enc_in[0][0 * 2 + j] = (enc_in[0][1 * 2 + j] + enc_in[0][6 * 2 + j]) / 2\n",
    "                # Neck/Nose\n",
    "                enc_in[0][14 * 2 + j] = (enc_in[0][15 * 2 + j] + enc_in[0][12 * 2 + j]) / 2\n",
    "                # Thorax\n",
    "                enc_in[0][13 * 2 + j] = 2 * enc_in[0][12 * 2 + j] - enc_in[0][14 * 2 + j]\n",
    "\n",
    "            # set spine\n",
    "            spine_x = enc_in[0][24]\n",
    "            spine_y = enc_in[0][25]\n",
    "\n",
    "            enc_in = enc_in[:, dim_to_use_2d]\n",
    "            mu = data_mean_2d[dim_to_use_2d]\n",
    "            stddev = data_std_2d[dim_to_use_2d]\n",
    "            enc_in = np.divide((enc_in - mu), stddev)\n",
    "\n",
    "            dp = 1.0\n",
    "            dec_out = np.zeros((1, 48))\n",
    "            dec_out[0] = [0 for i in range(48)]\n",
    "            _, _, poses3d = model.step(sess, enc_in, dec_out, dp, isTraining=False)\n",
    "            all_poses_3d = []\n",
    "            enc_in = data_utils.unNormalizeData(enc_in, data_mean_2d, data_std_2d, dim_to_ignore_2d)\n",
    "            poses3d = data_utils.unNormalizeData(poses3d, data_mean_3d, data_std_3d, dim_to_ignore_3d)\n",
    "            gs1 = gridspec.GridSpec(1, 1)\n",
    "            gs1.update(wspace=-0.00, hspace=0.05)  # set the spacing between axes.\n",
    "            plt.axis('off')\n",
    "            all_poses_3d.append( poses3d )\n",
    "            enc_in, poses3d = map( np.vstack, [enc_in, all_poses_3d] )\n",
    "            subplot_idx, exidx = 1, 1\n",
    "            _max = 0\n",
    "            _min = 10000\n",
    "\n",
    "            for i in range(poses3d.shape[0]):\n",
    "                for j in range(32):\n",
    "                    tmp = poses3d[i][j * 3 + 2]\n",
    "                    poses3d[i][j * 3 + 2] = poses3d[i][j * 3 + 1]\n",
    "                    poses3d[i][j * 3 + 1] = tmp\n",
    "                    if poses3d[i][j * 3 + 2] > _max:\n",
    "                        _max = poses3d[i][j * 3 + 2]\n",
    "                    if poses3d[i][j * 3 + 2] < _min:\n",
    "                        _min = poses3d[i][j * 3 + 2]\n",
    "\n",
    "            for i in range(poses3d.shape[0]):\n",
    "                for j in range(32):\n",
    "                    poses3d[i][j * 3 + 2] = _max - poses3d[i][j * 3 + 2] + _min\n",
    "                    poses3d[i][j * 3] += (spine_x - 630)\n",
    "                    poses3d[i][j * 3 + 2] += (500 - spine_y)\n",
    "\n",
    "            # Plot 3d predictions\n",
    "            ax = plt.subplot(gs1[subplot_idx - 1], projection='3d')\n",
    "            ax.view_init(18, -70)    \n",
    "\n",
    "            if FLAGS.cache_on_fail:\n",
    "                if np.min(poses3d) < -1000:\n",
    "                    poses3d = before_pose\n",
    "\n",
    "            p3d = poses3d\n",
    "            logger.info(\"frame score {0}\".format(np.min(poses3d)))\n",
    "            x,y,z = [[] for _ in range(3)]\n",
    "            if not poses3d is None:\n",
    "                to_export = poses3d.tolist()[0]\n",
    "            else:\n",
    "                to_export = [0.0 for _ in range(96)]\n",
    "            logger.debug(\"export {0}\".format(to_export))\n",
    "            for o in range(0, len(to_export), 3):\n",
    "                x.append(to_export[o])\n",
    "                y.append(to_export[o+1])\n",
    "                z.append(to_export[o+2])\n",
    "            # pdb.set_trace()\n",
    "            xx = p3d[0][0]\n",
    "            yy = p3d[0][1]\n",
    "            zz = p3d[0][2]\n",
    "            for o in range(0, len(p3d[0]), 3):\n",
    "                p3d[0][o] -= xx\n",
    "                p3d[0][o+1] -= yy\n",
    "                p3d[0][o+2] -= zz\n",
    "            export_units[frame]={}\n",
    "            # pdb.set_trace()\n",
    "            for jnt_index, (_x, _y, _z) in enumerate(zip(x,y,z)):\n",
    "                export_units[frame][jnt_index] = {\"translate\": [_x, _y, _z]}\n",
    "               \n",
    "            viz.show3Dpose(p3d, ax, lcolor=\"#9b59b6\", rcolor=\"#2ecc71\")\n",
    "            save3Djson(p3d , frame)\n",
    "            pngName = 'F:\\\\WTF\\cs\\\\thorn-jmh\\\\3d-pose-baseline\\\\test\\\\gif_output\\\\pose_frame_{0}.png'.format(str(frame).zfill(12))\n",
    "            #TODO:\n",
    "            # pdb.set_trace()\n",
    "            plt.savefig(pngName)\n",
    "            if FLAGS.write_gif:\n",
    "                png_lib.append(imageio.imread(pngName))\n",
    "\n",
    "            if FLAGS.cache_on_fail:\n",
    "                before_pose = poses3d\n",
    "\n",
    "    if FLAGS.write_gif:\n",
    "        if FLAGS.interpolation:\n",
    "            #take every frame on gif_fps * multiplier_inv\n",
    "            png_lib = np.array([png_lib[png_image] for png_image in range(0,len(png_lib), int(multiplier_inv)) ])\n",
    "        logger.info(\"creating Gif gif_output/animation.gif, please Wait!\")\n",
    "        imageio.mimsave('F:\\\\WTF\\cs\\\\thorn-jmh\\\\3d-pose-baseline\\\\test\\\\gif_output\\\\animation.gif', png_lib, fps=FLAGS.gif_fps)\n",
    "        # TODO:\n",
    "\n",
    "    # _out_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'maya/3d_data.json')\n",
    "    # twod_out_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'maya/2d_data.json')\n",
    "    # with open(_out_file, 'w') as outfile:\n",
    "    #     logger.info(\"exported maya json to {0}\".format(_out_file))\n",
    "    #     json.dump(export_units, outfile)\n",
    "    # with open(twod_out_file, 'w') as outfile:\n",
    "    #     logger.info(\"exported maya json to {0}\".format(twod_out_file))\n",
    "    #     json.dump(twod_export_units, outfile)\n",
    "    \n",
    "\n",
    "    logger.info(\"Done!\".format(pngName))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    openpose_output_dir = FLAGS.pose_estimation_json\n",
    "    \n",
    "    level = {0:logging.ERROR,\n",
    "             1:logging.WARNING,\n",
    "             2:logging.INFO,\n",
    "             3:logging.DEBUG}\n",
    "\n",
    "    logger.setLevel(level[FLAGS.verbose])\n",
    "\n",
    "\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3952f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dbl",
   "language": "python",
   "name": "3dbaseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
